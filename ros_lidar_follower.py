#!/usr/bin/env python3

import rospy
import cv2
import numpy as np
import time
import os
import json
import math
from enum import Enum
import requests

from jetbot import Robot
import onnxruntime as ort
from pyzbar.pyzbar import decode
import paho.mqtt.client as mqtt
from sensor_msgs.msg import LaserScan, Image
from opposite_detector import SimpleOppositeDetector

from map_navigator import MapNavigator

class RobotState(Enum):
    DRIVING_STRAIGHT = 1
    LINE_VALIDATION = 1.5
    APPROACHING_INTERSECTION = 2
    HANDLING_EVENT = 3
    LEAVING_INTERSECTION = 4
    REACQUIRING_LINE = 5
    DEAD_END = 6
    GOAL_REACHED = 7

class Direction(Enum):
    NORTH, EAST, SOUTH, WEST = 0, 1, 2, 3

class JetBotController:
    def __init__(self):
        rospy.loginfo("ƒêang kh·ªüi t·∫°o JetBot Event-Driven Controller...")
        self.setup_parameters()
        self.initialize_hardware()
        self.initialize_yolo()
        self.initialize_mqtt()

        self.video_writer = None
        self.initialize_video_writer()

        self.navigator = MapNavigator(self.MAP_FILE_PATH)
        self.current_node_id = self.navigator.start_node
        self.target_node_id = None
        self.planned_path = None
        self.banned_edges = []
        self.plan_initial_route()

        self.latest_scan = None
        self.latest_image = None
        self.detector = SimpleOppositeDetector()
        
        # Initialize angle analyzer for line/lidar comparison
        self.angle_analysis_enabled = True
        self.last_angle_analysis_time = 0
        self.angle_analysis_interval = 2.0  # Analyze every 2 seconds
        
        rospy.Subscriber('/scan', LaserScan, self.detector.callback)
        rospy.Subscriber('/csi_cam_0/image_raw', Image, self.camera_callback)
        rospy.loginfo("ƒê√£ ƒëƒÉng k√Ω v√†o c√°c topic /scan v√† /csi_cam_0/image_raw.")
        self.state_change_time = rospy.get_time()
        self.line_validation_attempts = 0  # Counter cho LINE_VALIDATION state
        self._set_state(RobotState.DRIVING_STRAIGHT, initial=True)
        rospy.loginfo("Kh·ªüi t·∫°o ho√†n t·∫•t. S·∫µn s√†ng ho·∫°t ƒë·ªông.")

    def plan_initial_route(self): 
        """L·∫≠p k·∫ø ho·∫°ch ƒë∆∞·ªùng ƒëi ban ƒë·∫ßu t·ª´ ƒëi·ªÉm xu·∫•t ph√°t ƒë·∫øn ƒë√≠ch."""
        rospy.loginfo(f"ƒêang l·∫≠p k·∫ø ho·∫°ch t·ª´ node {self.navigator.start_node} ƒë·∫øn {self.navigator.end_node}...")
        self.planned_path = self.navigator.find_path(
            self.navigator.start_node, 
            self.navigator.end_node,
            self.banned_edges
        )
        if self.planned_path and len(self.planned_path) > 1:
            self.target_node_id = self.planned_path[1]
            rospy.loginfo(f"ƒê√£ t√¨m th·∫•y ƒë∆∞·ªùng ƒëi: {self.planned_path}. ƒê√≠ch ƒë·∫øn ƒë·∫ßu ti√™n: {self.target_node_id}")
        else:
            rospy.logerr("Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng ƒëi ho·∫∑c ƒë∆∞·ªùng ƒëi qu√° ng·∫Øn!")
            self._set_state(RobotState.DEAD_END)

    def initialize_video_writer(self):
        """Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng VideoWriter."""
        try:
            # K√≠ch th∆∞·ªõc video s·∫Ω gi·ªëng k√≠ch th∆∞·ªõc ·∫£nh robot x·ª≠ l√Ω
            frame_size = (self.WIDTH, self.HEIGHT)
            self.video_writer = cv2.VideoWriter(self.VIDEO_OUTPUT_FILENAME, 
                                                self.VIDEO_FOURCC, 
                                                self.VIDEO_FPS, 
                                                frame_size)
            if self.video_writer.isOpened():
                rospy.loginfo(f"B·∫Øt ƒë·∫ßu ghi video v√†o file '{self.VIDEO_OUTPUT_FILENAME}'")
            else:
                rospy.logerr("Kh√¥ng th·ªÉ m·ªü file video ƒë·ªÉ ghi.")
                self.video_writer = None
        except Exception as e:
            rospy.logerr(f"L·ªói khi kh·ªüi t·∫°o VideoWriter: {e}")
            self.video_writer = None

    def draw_debug_info(self, image):
        """V·∫Ω c√°c th√¥ng tin g·ª° l·ªói l√™n m·ªôt khung h√¨nh."""
        if image is None:
            return None
        
        debug_frame = image.copy()
        
        # 1. V·∫Ω c√°c ROI
        # ROI Ch√≠nh (m√†u xanh l√°)
        cv2.rectangle(debug_frame, (0, self.ROI_Y), (self.WIDTH-1, self.ROI_Y + self.ROI_H), (0, 255, 0), 1)
        # ROI D·ª± b√°o (m√†u v√†ng)
        cv2.rectangle(debug_frame, (0, self.LOOKAHEAD_ROI_Y), (self.WIDTH-1, self.LOOKAHEAD_ROI_Y + self.LOOKAHEAD_ROI_H), (0, 255, 255), 1)

        # 2. V·∫Ω tr·∫°ng th√°i hi·ªán t·∫°i
        state_text = f"State: {self.current_state.name if self.current_state else 'None'}"
        cv2.putText(debug_frame, state_text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
        
        # 3. V·∫Ω line v√† tr·ªçng t√¢m (n·∫øu robot ƒëang b√°m line)
        if self.current_state == RobotState.DRIVING_STRAIGHT:
            # L·∫•y line center c·ªßa ROI Ch√≠nh
            line_center = self._get_line_center(image, self.ROI_Y, self.ROI_H)
            if line_center is not None:
                # V·∫Ω m·ªôt ƒë∆∞·ªùng th·∫≥ng ƒë·ª©ng m√†u ƒë·ªè t·∫°i v·ªã tr√≠ tr·ªçng t√¢m
                cv2.line(debug_frame, (line_center, self.ROI_Y), (line_center, self.ROI_Y + self.ROI_H), (0, 0, 255), 2)

        return debug_frame

    def setup_parameters(self):
        self.WIDTH, self.HEIGHT = 300, 300
        self.BASE_SPEED = 0.16
        self.TURN_SPEED = 0.2
        self.TURN_DURATION_90_DEG = 0.8
        self.ROI_Y = int(self.HEIGHT * 0.85)
        self.ROI_H = int(self.HEIGHT * 0.15)
        self.ROI_CENTER_WIDTH_PERCENT = 0.5
        self.LOOKAHEAD_ROI_Y = int(self.HEIGHT * 0.60) # V·ªã tr√≠ Y cao h∆°n
        self.LOOKAHEAD_ROI_H = int(self.HEIGHT * 0.15) # Chi·ªÅu cao t∆∞∆°ng t·ª±

        self.CORRECTION_GAIN = 0.5
        self.SAFE_ZONE_PERCENT = 0.3
        self.LINE_COLOR_LOWER = np.array([0, 0, 0])
        self.LINE_COLOR_UPPER = np.array([180, 255, 75])
        self.INTERSECTION_CLEARANCE_DURATION = 1.5
        self.INTERSECTION_APPROACH_DURATION = 0.5
        self.LINE_REACQUIRE_TIMEOUT = 3.0
        self.SCAN_PIXEL_THRESHOLD = 100
        self.YOLO_MODEL_PATH = "models/best.onnx"
        self.YOLO_CONF_THRESHOLD = 0.6
        self.YOLO_INPUT_SIZE = (640, 640)
        self.YOLO_CLASS_NAMES = ['N', 'E', 'W', 'S', 'NN', 'NE', 'NW', 'NS', 'math']
        self.PRESCRIPTIVE_SIGNS = {'N', 'E', 'W', 'S'}
        self.PROHIBITIVE_SIGNS = {'NN', 'NE', 'NW', 'NS'}
        self.DATA_ITEMS = {'qr_code', 'math_problem'}
        self.MQTT_BROKER = "localhost"; self.MQTT_PORT = 1883
        self.MQTT_DATA_TOPIC = "jetbot/corrected_event_data"
        self.current_state = None
        self.DIRECTIONS = [Direction.NORTH, Direction.EAST, Direction.SOUTH, Direction.WEST]
        self.current_direction_index = 1
        self.ANGLE_TO_FACE_SIGN_MAP = {d: a for d, a in zip(self.DIRECTIONS, [45, -45, -135, 135])}
        self.MAX_CORRECTION_ADJ = 0.12
        self.MAP_FILE_PATH = "map.json"
        self.LABEL_TO_DIRECTION_ENUM = {'N': Direction.NORTH, 'E': Direction.EAST, 'S': Direction.SOUTH, 'W': Direction.WEST}
        self.VIDEO_OUTPUT_FILENAME = 'jetbot_run.avi'
        self.VIDEO_FPS = 20  # N√™n kh·ªõp v·ªõi rospy.Rate c·ªßa b·∫°n
        # Codec 'MJPG' r·∫•t ph·ªï bi·∫øn v√† t∆∞∆°ng th√≠ch t·ªët
        self.VIDEO_FOURCC = cv2.VideoWriter_fourcc(*'MJPG')
        
        # Parameters cho LINE_VALIDATION state
        self.LINE_VALIDATION_TIMEOUT = 2.0  # Th·ªùi gian t·ªëi ƒëa ƒë·ªÉ validate line position
        self.LINE_CENTER_TOLERANCE = 0.2    # T·ª∑ l·ªá cho ph√©p line l·ªách kh·ªèi center (20% width)
        self.LINE_VALIDATION_ATTEMPTS = 8   # S·ªë l·∫ßn th·ª≠ validate t·ªëi ƒëa

    def initialize_hardware(self):
        try:
            self.robot = Robot()
            rospy.loginfo("Ph·∫ßn c·ª©ng JetBot (ƒë·ªông c∆°) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")
        except Exception as e:
            rospy.logwarn(f"Kh√¥ng t√¨m th·∫•y ph·∫ßn c·ª©ng JetBot, s·ª≠ d·ª•ng Mock object. L·ªói: {e}")
            from unittest.mock import Mock
            self.robot = Mock()

    def initialize_yolo(self):
        """T·∫£i m√¥ h√¨nh YOLO v√†o ONNX Runtime."""
        try:
            self.yolo_session = ort.InferenceSession(self.YOLO_MODEL_PATH, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
            rospy.loginfo("T·∫£i m√¥ h√¨nh YOLO th√†nh c√¥ng.")
        except Exception as e:
            rospy.logerr(f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh YOLO t·ª´ '{self.YOLO_MODEL_PATH}'. L·ªói: {e}")
            self.yolo_session = None

    def numpy_nms(self, boxes, scores, iou_threshold):
        """
        Th·ª±c hi·ªán Non-Maximum Suppression (NMS) b·∫±ng NumPy.
        :param boxes: list c√°c bounding box, m·ªói box l√† [x1, y1, x2, y2]
        :param scores: list c√°c ƒëi·ªÉm tin c·∫≠y t∆∞∆°ng ·ª©ng
        :param iou_threshold: ng∆∞·ª°ng IoU ƒë·ªÉ lo·∫°i b·ªè c√°c box tr√πng l·∫∑p
        :return: list c√°c ch·ªâ s·ªë (indices) c·ªßa c√°c box ƒë∆∞·ª£c gi·ªØ l·∫°i
        """
        # Chuy·ªÉn ƒë·ªïi sang NumPy array ƒë·ªÉ t√≠nh to√°n vector h√≥a
        x1 = np.array([b[0] for b in boxes])
        y1 = np.array([b[1] for b in boxes])
        x2 = np.array([b[2] for b in boxes])
        y2 = np.array([b[3] for b in boxes])

        areas = (x2 - x1 + 1) * (y2 - y1 + 1)
        # S·∫Øp x·∫øp c√°c box theo ƒëi·ªÉm tin c·∫≠y gi·∫£m d·∫ßn
        order = scores.argsort()[::-1]

        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            
            # T√≠nh to√°n IoU (Intersection over Union)
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])

            w = np.maximum(0.0, xx2 - xx1 + 1)
            h = np.maximum(0.0, yy2 - yy1 + 1)
            intersection = w * h
            
            iou = intersection / (areas[i] + areas[order[1:]] - intersection)

            # Gi·ªØ l·∫°i c√°c box c√≥ IoU nh·ªè h∆°n ng∆∞·ª°ng
            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]

        return np.array(keep)

    def detect_with_yolo(self, image):
        """
        Th·ª±c hi·ªán nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng b·∫±ng YOLOv8 v√† h·∫≠u x·ª≠ l√Ω k·∫øt qu·∫£ ƒë√∫ng c√°ch.
        """
        if self.yolo_session is None: return []

        original_height, original_width = image.shape[:2]

        img_resized = cv2.resize(image, self.YOLO_INPUT_SIZE)
        img_data = np.array(img_resized, dtype=np.float32) / 255.0
        img_data = np.transpose(img_data, (2, 0, 1))  # HWC to CHW
        input_tensor = np.expand_dims(img_data, axis=0)  # Add batch dimension

        input_name = self.yolo_session.get_inputs()[0].name
        outputs = self.yolo_session.run(None, {input_name: input_tensor})

        # L·∫•y output th√¥, output c·ªßa YOLOv8 th∆∞·ªùng c√≥ shape (1, 84, 8400) ho·∫∑c t∆∞∆°ng t·ª±
        # Ch√∫ng ta c·∫ßn transpose n√≥ th√†nh (1, 8400, 84) ƒë·ªÉ d·ªÖ x·ª≠ l√Ω
        predictions = np.squeeze(outputs[0]).T

        # L·ªçc c√°c box c√≥ ƒëi·ªÉm tin c·∫≠y (objectness score) th·∫•p
        # C·ªôt 4 trong predictions l√† ƒëi·ªÉm tin c·∫≠y t·ªïng th·ªÉ c·ªßa box
        scores = np.max(predictions[:, 4:], axis=1)
        predictions = predictions[scores > self.YOLO_CONF_THRESHOLD, :]
        scores = scores[scores > self.YOLO_CONF_THRESHOLD]

        if predictions.shape[0] == 0:
            rospy.loginfo("YOLO kh√¥ng ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng n√†o v∆∞·ª£t ng∆∞·ª°ng tin c·∫≠y.")
            return []

        # L·∫•y class_id c√≥ ƒëi·ªÉm cao nh·∫•t
        class_ids = np.argmax(predictions[:, 4:], axis=1)

        # L·∫•y t·ªça ƒë·ªô box v√† chuy·ªÉn ƒë·ªïi v·ªÅ ·∫£nh g·ªëc
        x, y, w, h = predictions[:, 0], predictions[:, 1], predictions[:, 2], predictions[:, 3]
        
        # T√≠nh to√°n t·ª∑ l·ªá scale ƒë·ªÉ chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô
        x_scale = original_width / self.YOLO_INPUT_SIZE[0]
        y_scale = original_height / self.YOLO_INPUT_SIZE[1]

        # Chuy·ªÉn t·ª´ [center_x, center_y, width, height] sang [x1, y1, x2, y2]
        x1 = (x - w / 2) * x_scale
        y1 = (y - h / 2) * y_scale
        x2 = (x + w / 2) * x_scale
        y2 = (y + h / 2) * y_scale
        
        # Chuy·ªÉn th√†nh list c√°c box v√† scores
        boxes = np.column_stack((x1, y1, x2, y2)).tolist()
        
        # 4. Th·ª±c hi·ªán Non-Maximum Suppression (NMS)
        # ƒê√¢y l√† m·ªôt b∆∞·ªõc c·ª±c k·ª≥ quan tr·ªçng ƒë·ªÉ lo·∫°i b·ªè c√°c box tr√πng l·∫∑p
        # OpenCV cung c·∫•p m·ªôt h√†m NMS hi·ªáu qu·∫£
        nms_threshold = 0.45 # Ng∆∞·ª°ng IOU ƒë·ªÉ lo·∫°i b·ªè box
        indices = self.numpy_nms(np.array(boxes), scores, nms_threshold)
        
        if len(indices) == 0:
            rospy.loginfo("YOLO: Sau NMS, kh√¥ng c√≤n ƒë·ªëi t∆∞·ª£ng n√†o.")
            return []

        # 5. T·∫°o danh s√°ch k·∫øt qu·∫£ cu·ªëi c√πng
        final_detections = []
        for i in indices.flatten():
            final_detections.append({
                'class_name': self.YOLO_CLASS_NAMES[class_ids[i]],
                'confidence': float(scores[i]),
                'box': [int(coord) for coord in boxes[i]] # Chuy·ªÉn t·ªça ƒë·ªô sang int
            })

        rospy.loginfo(f"YOLO ƒë√£ ph√°t hi·ªán {len(final_detections)} ƒë·ªëi t∆∞·ª£ng cu·ªëi c√πng.")
        return final_detections

    def initialize_mqtt(self):
        self.mqtt_client = mqtt.Client()
        def on_connect(client, userdata, flags, rc): rospy.loginfo(f"K·∫øt n·ªëi MQTT: {'Th√†nh c√¥ng' if rc == 0 else 'Th·∫•t b·∫°i'}")
        self.mqtt_client.on_connect = on_connect
        try:
            self.mqtt_client.connect(self.MQTT_BROKER, self.MQTT_PORT, 60)
            self.mqtt_client.loop_start()
        except Exception as e: rospy.logerr(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi MQTT: {e}")
    
    def _set_state(self, new_state, initial=False):
        if self.current_state != new_state:
            if not initial: rospy.loginfo(f"Chuy·ªÉn tr·∫°ng th√°i: {self.current_state.name if self.current_state else 'None'} -> {new_state.name}")
            
            # Reset line validation counter khi r·ªùi kh·ªèi LINE_VALIDATION state
            if self.current_state == RobotState.LINE_VALIDATION and new_state != RobotState.LINE_VALIDATION:
                self.line_validation_attempts = 0
                
            self.current_state = new_state
            self.state_change_time = rospy.get_time()

    def camera_callback(self, image_msg):
        try:
            if image_msg.encoding.endswith('compressed'):
                np_arr = np.frombuffer(image_msg.data, np.uint8)
                cv_image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            else:
                cv_image = np.frombuffer(image_msg.data, dtype=np.uint8).reshape(image_msg.height, image_msg.width, -1)
            if 'rgb' in image_msg.encoding: cv_image = cv2.cvtColor(cv_image, cv2.COLOR_RGB2BGR)
            self.latest_image = cv2.resize(cv_image, (self.WIDTH, self.HEIGHT))
        except Exception as e: rospy.logerr(f"L·ªói chuy·ªÉn ƒë·ªïi ·∫£nh: {e}")

    def run(self):
        rospy.loginfo("B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p. ƒê·ª£i 3 gi√¢y..."); time.sleep(3); rospy.loginfo("H√†nh tr√¨nh b·∫Øt ƒë·∫ßu!")
        self.detector.start_scanning()
        rate = rospy.Rate(20)
        while not rospy.is_shutdown():
            # ===================================================================
            # TR·∫†NG TH√ÅI 1: ƒêANG B√ÅM LINE (DRIVING_STRAIGHT)
            # ===================================================================
            if self.current_state == RobotState.DRIVING_STRAIGHT:
                if self.latest_image is None:
                    rospy.logwarn_throttle(5, "ƒêang ch·ªù d·ªØ li·ªáu h√¨nh ·∫£nh t·ª´ topic camera...")
                    self.robot.stop()
                    rate.sleep()
                    continue

                # --- B∆Ø·ªöC 1: KI·ªÇM TRA T√çN HI·ªÜU ∆ØU TI√äN CAO (LiDAR) ---
                # ƒê√¢y l√† t√≠n hi·ªáu ƒë√°ng tin c·∫≠y nh·∫•t, n·∫øu n√≥ k√≠ch ho·∫°t, x·ª≠ l√Ω ngay.
                if self.detector.process_detection():
                    rospy.loginfo("S·ª∞ KI·ªÜN (LiDAR): Ph√°t hi·ªán giao l·ªô. D·ª´ng ngay l·∫≠p t·ª©c.")
                    self.robot.stop()
                    time.sleep(0.5) # Ch·ªù robot d·ª´ng h·∫≥n

                    # C·∫≠p nh·∫≠t v·ªã tr√≠ hi·ªán t·∫°i (ƒë√£ ƒë·∫øn ƒë√≠ch) v√† x·ª≠ l√Ω
                    self.current_node_id = self.target_node_id
                    rospy.loginfo(f"==> ƒê√É ƒê·∫æN node {self.current_node_id}.")

                    if self.current_node_id == self.navigator.end_node:
                        rospy.loginfo("ƒê√É ƒê·∫æN ƒê√çCH CU·ªêI C√ôNG!")
                        self._set_state(RobotState.GOAL_REACHED)
                    else:
                        self._set_state(RobotState.HANDLING_EVENT)
                        self.handle_intersection()
                    continue # B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p m·ªõi v·ªõi tr·∫°ng th√°i m·ªõi

                # --- B∆Ø·ªöC 2: LOGIC "NH√åN XA H∆†N" V·ªöI ROI D·ª∞ B√ÅO ---
                # N·∫øu LiDAR im l·∫∑ng, ki·ªÉm tra xem v·∫°ch k·∫ª c√≥ s·∫Øp bi·∫øn m·∫•t ·ªü ph√≠a xa kh√¥ng.
                lookahead_line_center = self._get_line_center(self.latest_image, self.LOOKAHEAD_ROI_Y, self.LOOKAHEAD_ROI_H)

                if lookahead_line_center is None:
                    rospy.logwarn("S·ª∞ KI·ªÜN (D·ª± b√°o): V·∫°ch k·∫ª ƒë∆∞·ªùng bi·∫øn m·∫•t ·ªü ph√≠a xa. Chu·∫©n b·ªã v√†o giao l·ªô.")
                    # H√†nh ƒë·ªông ph√≤ng ng·ª´a: chuy·ªÉn sang tr·∫°ng th√°i ƒëi th·∫≥ng v√†o giao l·ªô.
                    self._set_state(RobotState.APPROACHING_INTERSECTION)
                    continue # B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p m·ªõi v·ªõi tr·∫°ng th√°i m·ªõi

                # --- B∆Ø·ªöC 3: B√ÅM LINE B√åNH TH∆Ø·ªúNG (N·∫æU PH√çA TR∆Ø·ªöC AN TO√ÄN) ---
                # Ch·ªâ khi c·∫£ LiDAR v√† ROI D·ª± b√°o ƒë·ªÅu ·ªïn, ta m·ªõi th·ª±c hi·ªán b√°m line.
                execution_line_center = self._get_line_center(self.latest_image, self.ROI_Y, self.ROI_H)

                if execution_line_center is not None:
                    # Ki·ªÉm tra xem line c√≥ n·∫±m trong kho·∫£ng h·ª£p l·ªá kh√¥ng tr∆∞·ªõc khi b√°m
                    if not self._is_line_in_valid_range(self.latest_image):
                        rospy.logwarn("S·ª∞ KI·ªÜN: Line position kh√¥ng h·ª£p l·ªá, chuy·ªÉn sang LINE_VALIDATION ƒë·ªÉ ki·ªÉm tra.")
                        self.line_validation_attempts = 0  # Reset counter
                        self._set_state(RobotState.LINE_VALIDATION)
                        continue
                    
                    # An to√†n ƒë·ªÉ b√°m line, v√¨ ch√∫ng ta bi·∫øt ph√≠a tr∆∞·ªõc kh√¥ng c√≥ giao l·ªô ƒë·ªôt ng·ªôt.
                    self.correct_course(execution_line_center)
                    
                    # Ph√¢n t√≠ch v√† in g√≥c line (n·∫øu ƒë∆∞·ª£c b·∫≠t)
                    if self.angle_analysis_enabled:
                        self.analyze_and_print_line_angles()
                else:
                    # Tr∆∞·ªùng h·ª£p hi·∫øm: ROI xa th·∫•y line nh∆∞ng ROI g·∫ßn l·∫°i kh√¥ng. D·ª´ng l·∫°i cho an to√†n.
                    rospy.logwarn("Tr·∫°ng th√°i kh√¥ng nh·∫•t qu√°n: ROI xa th·∫•y line, ROI g·∫ßn kh√¥ng th·∫•y. T·∫°m d·ª´ng an to√†n.")
                    self.robot.stop()

            # ===================================================================
            # TR·∫†NG TH√ÅI 1.5: KI·ªÇM TRA V√Ä X√ÅC TH·ª∞C V·ªä TR√ç LINE (LINE_VALIDATION)
            # ===================================================================
            elif self.current_state == RobotState.LINE_VALIDATION:
                if self.latest_image is None:
                    rospy.logwarn("LINE_VALIDATION: Ch·ªù d·ªØ li·ªáu camera...")
                    self.robot.stop()
                    rate.sleep()
                    continue

                # Ki·ªÉm tra line c√≥ n·∫±m trong kho·∫£ng h·ª£p l·ªá kh√¥ng
                if self._is_line_in_valid_range(self.latest_image):
                    rospy.loginfo("LINE_VALIDATION: Line position h·ª£p l·ªá, ti·∫øp t·ª•c b√°m line.")
                    self._set_state(RobotState.DRIVING_STRAIGHT)
                    continue
                else:
                    # Line kh√¥ng h·ª£p l·ªá, th·ª≠ ƒëi·ªÅu ch·ªânh
                    self.line_validation_attempts += 1
                    rospy.logwarn(f"LINE_VALIDATION: Line kh√¥ng h·ª£p l·ªá, l·∫ßn th·ª≠ {self.line_validation_attempts}/{self.LINE_VALIDATION_ATTEMPTS}")
                    
                    if self.line_validation_attempts >= self.LINE_VALIDATION_ATTEMPTS:
                        rospy.logerr("LINE_VALIDATION: ƒê√£ th·ª≠ t·ªëi ƒëa, chuy·ªÉn sang t√¨m ki·∫øm line m·ªõi.")
                        self._set_state(RobotState.REACQUIRING_LINE)
                        continue
                    
                    # Th·ª≠ ƒëi·ªÅu ch·ªânh nh·∫π ƒë·ªÉ t√¨m l·∫°i line
                    line_center = self._get_line_center(self.latest_image, self.ROI_Y, self.ROI_H)
                    if line_center is not None:
                        error = line_center - (self.WIDTH / 2)
                        if abs(error) > 0:
                            # ƒêi·ªÅu ch·ªânh nh·∫π v·ªÅ ph√≠a line
                            adj = np.clip(error / (self.WIDTH / 2) * 0.3, -0.1, 0.1)
                            self.robot.set_motors(self.BASE_SPEED * 0.5 + adj, self.BASE_SPEED * 0.5 - adj)
                        else:
                            self.robot.set_motors(self.BASE_SPEED * 0.5, self.BASE_SPEED * 0.5)
                    else:
                        self.robot.stop()
                
                # Timeout check
                if rospy.get_time() - self.state_change_time > self.LINE_VALIDATION_TIMEOUT:
                    rospy.logwarn("LINE_VALIDATION: Timeout, chuy·ªÉn sang t√¨m ki·∫øm line m·ªõi.")
                    self._set_state(RobotState.REACQUIRING_LINE)

            # ===================================================================
            # TR·∫†NG TH√ÅI 2: ƒêANG TI·∫æN V√ÄO GIAO L·ªò (APPROACHING_INTERSECTION)
            # ===================================================================
            elif self.current_state == RobotState.APPROACHING_INTERSECTION:
                # ƒêi th·∫≥ng m·ªôt ƒëo·∫°n ng·∫Øn ƒë·ªÉ v√†o trung t√¢m giao l·ªô
                self.robot.set_motors(self.BASE_SPEED, self.BASE_SPEED)
                
                if rospy.get_time() - self.state_change_time > self.INTERSECTION_APPROACH_DURATION:
                    rospy.loginfo("ƒê√£ ti·∫øn v√†o trung t√¢m giao l·ªô. D·ª´ng l·∫°i ƒë·ªÉ x·ª≠ l√Ω.")
                    self.robot.stop(); time.sleep(0.5)

                    self.current_node_id = self.target_node_id
                    rospy.loginfo(f"==> ƒê√É ƒê·∫æN node {self.current_node_id}.")

                    if self.current_node_id == self.navigator.end_node:
                        rospy.loginfo("ƒê√É ƒê·∫æN ƒê√çCH CU·ªêI C√ôNG!")
                        self._set_state(RobotState.GOAL_REACHED)
                    else:
                        self._set_state(RobotState.HANDLING_EVENT)
                        self.handle_intersection()

            # ===================================================================
            # TR·∫†NG TH√ÅI 3: ƒêANG R·ªúI KH·ªéI GIAO L·ªò (LEAVING_INTERSECTION)
            # ===================================================================
            elif self.current_state == RobotState.LEAVING_INTERSECTION:
                self.robot.set_motors(self.BASE_SPEED, self.BASE_SPEED)
                if rospy.get_time() - self.state_change_time > self.INTERSECTION_CLEARANCE_DURATION:
                    rospy.loginfo("ƒê√£ tho√°t kh·ªèi khu v·ª±c giao l·ªô. B·∫Øt ƒë·∫ßu t√¨m ki·∫øm line m·ªõi.")
                    self._set_state(RobotState.REACQUIRING_LINE)
            
            # ===================================================================
            # TR·∫†NG TH√ÅI 4: ƒêANG T√åM L·∫†I LINE (REACQUIRING_LINE)
            # ===================================================================
            elif self.current_state == RobotState.REACQUIRING_LINE:
                self.robot.set_motors(self.BASE_SPEED, self.BASE_SPEED)
                line_center_x = self._get_line_center(self.latest_image, self.ROI_Y, self.ROI_H)
                
                if line_center_x is not None:
                    rospy.loginfo("ƒê√£ t√¨m th·∫•y line m·ªõi! Chuy·ªÉn sang ch·∫ø ƒë·ªô b√°m line.")
                    self._set_state(RobotState.DRIVING_STRAIGHT)
                    continue
                
                if rospy.get_time() - self.state_change_time > self.LINE_REACQUIRE_TIMEOUT:
                    rospy.logerr("Kh√¥ng th·ªÉ t√¨m th·∫•y line m·ªõi sau khi r·ªùi giao l·ªô. D·ª´ng l·∫°i.")
                    self._set_state(RobotState.DEAD_END)

            # ===================================================================
            # TR·∫†NG TH√ÅI K·∫æT TH√öC (DEAD_END, GOAL_REACHED)
            # ===================================================================
            elif self.current_state == RobotState.DEAD_END:
                rospy.logwarn("ƒê√£ v√†o ng√µ c·ª•t ho·∫∑c g·∫∑p l·ªói kh√¥ng th·ªÉ ph·ª•c h·ªìi. D·ª´ng ho·∫°t ƒë·ªông."); self.robot.stop(); break
            elif self.current_state == RobotState.GOAL_REACHED: 
                rospy.loginfo("ƒê√É HO√ÄN TH√ÄNH NHI·ªÜM V·ª§. D·ª´ng ho·∫°t ƒë·ªông."); self.robot.stop(); break

            if self.video_writer is not None and self.latest_image is not None:
                # L·∫•y ·∫£nh g·ªëc, v·∫Ω th√¥ng tin l√™n, r·ªìi ghi
                debug_frame = self.draw_debug_info(self.latest_image)
                if debug_frame is not None:
                    self.video_writer.write(debug_frame)

            rate.sleep()
        self.cleanup()

    def cleanup(self):
        rospy.loginfo("D·ª´ng robot v√† gi·∫£i ph√≥ng t√†i nguy√™n..."); self.robot.stop()
        self.detector.stop_scanning(); self.mqtt_client.loop_stop(); self.mqtt_client.disconnect()
        rospy.loginfo("ƒê√£ gi·∫£i ph√≥ng t√†i nguy√™n. Ch∆∞∆°ng tr√¨nh k·∫øt th√∫c.")

    def map_absolute_to_relative(self, target_direction_label, current_robot_direction):
        """
        Chuy·ªÉn ƒë·ªïi h∆∞·ªõng tuy·ªát ƒë·ªëi ('N', 'E', 'S', 'W') th√†nh h√†nh ƒë·ªông t∆∞∆°ng ƒë·ªëi ('straight', 'left', 'right').
        V√≠ d·ª•: robot ƒëang h∆∞·ªõng B·∫ÆC (NORTH), m·ª•c ti√™u l√† ƒëi h∆∞·ªõng ƒê√îNG (EAST) -> h√†nh ƒë·ªông l√† 'right'.
        """
        target_dir = self.LABEL_TO_DIRECTION_ENUM.get(target_direction_label)
        if target_dir is None: return None

        current_idx = current_robot_direction.value
        target_idx = target_dir.value
        
        diff = (target_idx - current_idx + 4) % 4 
        
        if diff == 0:
            return 'straight'
        elif diff == 1:
            return 'right'
        elif diff == 3: 
            return 'left'
        else: 
            return 'turn_around'
        
    def map_relative_to_absolute(self, relative_action, current_robot_direction):
        """
        Chuy·ªÉn ƒë·ªïi h√†nh ƒë·ªông t∆∞∆°ng ƒë·ªëi ('straight', 'left', 'right') th√†nh h∆∞·ªõng tuy·ªát ƒë·ªëi ('N', 'E', 'S', 'W').
        """
        current_idx = current_robot_direction.value
        if relative_action == 'straight':
            target_idx = current_idx
        elif relative_action == 'right':
            target_idx = (current_idx + 1) % 4
        elif relative_action == 'left':
            target_idx = (current_idx - 1 + 4) % 4
        else:
            return None
        
        for label, direction in self.LABEL_TO_DIRECTION_ENUM.items():
            if direction.value == target_idx:
                return label
        return None
    
    def _get_line_center(self, image, roi_y, roi_h):
        """Ki·ªÉm tra s·ª± t·ªìn t·∫°i v√† v·ªã tr√≠ c·ªßa v·∫°ch k·∫ª trong m·ªôt ROI c·ª• th·ªÉ."""
        if image is None: return None
        roi = image[roi_y : roi_y + roi_h, :]
        
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        
        # B∆∞·ªõc 1: T·∫°o m·∫∑t n·∫° m√†u s·∫Øc nh∆∞ c≈©
        color_mask = cv2.inRange(hsv, self.LINE_COLOR_LOWER, self.LINE_COLOR_UPPER)
        
        # === B∆Ø·ªöC 2: T·∫†O M·∫∂T N·∫† T·∫¨P TRUNG (FOCUS MASK) ===
        focus_mask = np.zeros_like(color_mask)
        roi_height, roi_width = focus_mask.shape
        
        center_width = int(roi_width * self.ROI_CENTER_WIDTH_PERCENT)
        start_x = (roi_width - center_width) // 2
        end_x = start_x + center_width
        
        # V·∫Ω m·ªôt h√¨nh ch·ªØ nh·∫≠t tr·∫Øng ·ªü gi·ªØa
        cv2.rectangle(focus_mask, (start_x, 0), (end_x, roi_height), 255, -1)
        
        # === B∆Ø·ªöC 3: K·∫æT H·ª¢P HAI M·∫∂T N·∫† ===
        # Ch·ªâ gi·ªØ l·∫°i nh·ªØng pixel tr·∫Øng n√†o xu·∫•t hi·ªán ·ªü c·∫£ hai m·∫∑t n·∫°
        final_mask = cv2.bitwise_and(color_mask, focus_mask)

        # (T√πy ch·ªçn) Hi·ªÉn th·ªã mask ƒë·ªÉ debug
        # cv2.imshow("Color Mask", color_mask)
        # cv2.imshow("Focus Mask", focus_mask)
        # cv2.imshow("Final Mask", final_mask)
        # cv2.waitKey(1)

        # T√¨m contours tr√™n m·∫∑t n·∫° cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l·ªçc
        _, contours, _ = cv2.findContours(final_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return None
            
        c = max(contours, key=cv2.contourArea)
        
        if cv2.contourArea(c) < self.SCAN_PIXEL_THRESHOLD:
            return None

        M = cv2.moments(c)
        if M["m00"] > 0:
            # Quan tr·ªçng: Tr·ªçng t√¢m b√¢y gi·ªù ƒë∆∞·ª£c t√≠nh to√°n ch·ªâ d·ª±a tr√™n v·∫°ch k·∫ª trong khu v·ª±c trung t√¢m
            return int(M["m10"] / M["m00"])
        return None
    
    def _is_line_in_valid_range(self, image):
        """
        Ki·ªÉm tra xem v·∫°ch k·∫ª c√≥ n·∫±m trong kho·∫£ng h·ª£p l·ªá kh√¥ng.
        Returns: 
            - True n·∫øu line n·∫±m trong kho·∫£ng cho ph√©p
            - False n·∫øu line qu√° l·ªách ho·∫∑c kh√¥ng t√¨m th·∫•y
        """
        if image is None:
            return False
            
        line_center = self._get_line_center(image, self.ROI_Y, self.ROI_H)
        if line_center is None:
            return False
            
        image_center = self.WIDTH / 2
        max_deviation = self.WIDTH * self.LINE_CENTER_TOLERANCE
        deviation = abs(line_center - image_center)
        
        is_valid = deviation <= max_deviation
        
        rospy.loginfo(f"Line validation: center={line_center}, deviation={deviation:.1f}, max_allowed={max_deviation:.1f}, valid={is_valid}")
        return is_valid
    
    def calculate_line_angle_from_camera(self):
        """
        T√≠nh g√≥c c·ªßa line t·ª´ camera d·ª±a tr√™n v·ªã tr√≠ tr·ªçng t√¢m.
        Returns: (angle_degrees, confidence)
        """
        line_center = self._get_line_center(self.latest_image, self.ROI_Y, self.ROI_H)
        if line_center is None:
            return None, "NO_LINE_DETECTED"
        
        image_center = self.WIDTH / 2
        pixel_offset = line_center - image_center
        
        # Chuy·ªÉn ƒë·ªïi pixel offset th√†nh g√≥c (s·ª≠ d·ª•ng FOV 60 degrees)
        camera_fov = 60
        angle = (pixel_offset / image_center) * (camera_fov / 2)
        
        # ƒê√°nh gi√° confidence
        if abs(angle) < 3:
            confidence = "HIGH"
        elif abs(angle) < 10:
            confidence = "MEDIUM"
        else:
            confidence = "LOW"
        
        return angle, confidence
    
    def find_line_clusters_in_lidar(self):
        """
        T√¨m c√°c clusters c√≥ th·ªÉ l√† line trong d·ªØ li·ªáu LiDAR.
        """
        if self.detector.latest_scan is None:
            return []
        
        scan = self.detector.latest_scan
        ranges = np.array(scan.ranges)
        n = len(ranges)
        
        angle_increment_deg = math.degrees(scan.angle_increment)
        points_per_range = int(self.detector.angle_range / angle_increment_deg)
        
        line_clusters = []
        front_angle_range = 45  # ¬±45 degrees
        
        # Qu√©t theo t·ª´ng zone ·ªü ph√≠a tr∆∞·ªõc
        for start_idx in range(0, n, points_per_range // 2):
            end_idx = min(start_idx + points_per_range, n)
            if end_idx - start_idx < points_per_range // 2:
                continue
            
            center_idx = start_idx + (end_idx - start_idx) // 2
            center_angle = self.detector.index_to_angle(center_idx, scan)
            
            # Ch·ªâ x√©t c√°c zone ·ªü ph√≠a tr∆∞·ªõc
            if abs(center_angle) <= front_angle_range:
                cluster = self.detect_line_cluster_in_zone(ranges[start_idx:end_idx], center_angle)
                if cluster:
                    line_clusters.append(cluster)
        
        return line_clusters
    
    def detect_line_cluster_in_zone(self, zone_ranges, center_angle):
        """
        Ph√°t hi·ªán line cluster trong m·ªôt zone.
        """
        if len(zone_ranges) == 0:
            return None
        
        # L·ªçc c√°c ƒëi·ªÉm h·ª£p l·ªá (tƒÉng range ƒë·ªÉ detect line xa h∆°n)
        min_dist, max_dist = 0.15, 2.0
        valid_mask = ((zone_ranges >= min_dist) & 
                     (zone_ranges <= max_dist) & 
                     np.isfinite(zone_ranges))
        
        if np.sum(valid_mask) < 5:  # √çt nh·∫•t 5 ƒëi·ªÉm
            return None
        
        valid_ranges = zone_ranges[valid_mask]
        
        # Ki·ªÉm tra ƒë·∫∑c ƒëi·ªÉm line: kho·∫£ng c√°ch t∆∞∆°ng ƒë·ªëi ƒë·ªìng ƒë·ªÅu
        distance_variance = np.var(valid_ranges)
        
        if distance_variance <= 0.4:  # Line c√≥ variance th·∫•p
            return {
                'center_angle': center_angle,
                'distance': np.mean(valid_ranges),
                'point_count': len(valid_ranges),
                'variance': distance_variance
            }
        
        return None
    
    def calculate_line_angle_from_lidar(self):
        """
        T√≠nh g√≥c c·ªßa line d·ª±a tr√™n c√°c clusters t·ª´ LiDAR.
        """
        line_clusters = self.find_line_clusters_in_lidar()
        
        if len(line_clusters) < 1:
            return None, "NO_CLUSTERS_FOUND"
        
        # Weighted average d·ª±a tr√™n s·ªë ƒëi·ªÉm v√† kho·∫£ng c√°ch
        angles = [cluster['center_angle'] for cluster in line_clusters]
        distances = [cluster['distance'] for cluster in line_clusters]
        point_counts = [cluster['point_count'] for cluster in line_clusters]
        
        # T√≠nh tr·ªçng s·ªë (g·∫ßn h∆°n v√† nhi·ªÅu ƒëi·ªÉm h∆°n = tr·ªçng s·ªë cao h∆°n)
        weights = []
        for i in range(len(line_clusters)):
            weight = point_counts[i] / (distances[i] + 0.1)
            weights.append(weight)
        
        weights = np.array(weights)
        if np.sum(weights) > 0:
            weights = weights / np.sum(weights)  # Normalize
            weighted_angle = np.average(angles, weights=weights)
        else:
            weighted_angle = np.mean(angles)
        
        # ƒê√°nh gi√° confidence
        if len(line_clusters) >= 3:
            confidence = "HIGH"
        elif len(line_clusters) >= 2:
            confidence = "MEDIUM"
        else:
            confidence = "LOW"
        
        return weighted_angle, confidence
    
    def analyze_and_print_line_angles(self):
        """
        Ph√¢n t√≠ch v√† in ra g√≥c line t·ª´ camera v√† LiDAR.
        """
        current_time = rospy.get_time()
        
        # Ch·ªâ ph√¢n t√≠ch m·ªói interval seconds
        if current_time - self.last_angle_analysis_time < self.angle_analysis_interval:
            return
        
        self.last_angle_analysis_time = current_time
        
        camera_angle, camera_conf = self.calculate_line_angle_from_camera()
        lidar_angle, lidar_conf = self.calculate_line_angle_from_lidar()
        
        print("\n" + "="*60)
        print("üîç LINE ANGLE ANALYSIS")
        print(f"‚è∞ Time: {current_time:.1f}s")
        print("="*60)
        
        # Camera Analysis
        print(f"üì∑ CAMERA:")
        if camera_angle is not None:
            print(f"   ‚Ä¢ Angle: {camera_angle:+6.2f}¬∞ ({camera_conf})")
            if camera_angle > 5:
                print(f"   ‚Ä¢ Direction: RIGHT (line to the right)")
            elif camera_angle < -5:
                print(f"   ‚Ä¢ Direction: LEFT (line to the left)")
            else:
                print(f"   ‚Ä¢ Direction: STRAIGHT (centered)")
        else:
            print(f"   ‚Ä¢ Status: {camera_conf}")
        
        # LiDAR Analysis
        print(f"üì° LIDAR:")
        if lidar_angle is not None:
            clusters = self.find_line_clusters_in_lidar()
            print(f"   ‚Ä¢ Angle: {lidar_angle:+6.2f}¬∞ ({lidar_conf})")
            print(f"   ‚Ä¢ Clusters: {len(clusters)} found")
            for i, cluster in enumerate(clusters):
                print(f"     #{i+1}: {cluster['point_count']} pts @ {cluster['center_angle']:+5.1f}¬∞, "
                      f"dist={cluster['distance']:.2f}m")
        else:
            print(f"   ‚Ä¢ Status: {lidar_conf}")
        
        # Comparison
        if camera_angle is not None and lidar_angle is not None:
            angle_diff = abs(camera_angle - lidar_angle)
            print(f"üîÑ COMPARISON:")
            print(f"   ‚Ä¢ Difference: {angle_diff:.2f}¬∞")
            
            if angle_diff < 3:
                agreement = "EXCELLENT"
            elif angle_diff < 8:
                agreement = "GOOD"
            elif angle_diff < 15:
                agreement = "FAIR"
            else:
                agreement = "POOR"
            
            print(f"   ‚Ä¢ Agreement: {agreement}")
            
            # Combined recommendation
            if camera_conf == "HIGH" and lidar_conf == "HIGH":
                combined_angle = (camera_angle + lidar_angle) / 2
                print(f"   ‚Ä¢ Combined: {combined_angle:+6.2f}¬∞ (averaged)")
            elif camera_conf == "HIGH":
                print(f"   ‚Ä¢ Recommend: Use Camera ({camera_angle:+6.2f}¬∞)")
            elif lidar_conf == "HIGH":
                print(f"   ‚Ä¢ Recommend: Use LiDAR ({lidar_angle:+6.2f}¬∞)")
            else:
                combined_angle = (camera_angle + lidar_angle) / 2
                print(f"   ‚Ä¢ Combined: {combined_angle:+6.2f}¬∞ (with caution)")
        
        print("="*60 + "\n")
    
    def correct_course(self, line_center_x):
        """
        H√†m b√°m line an to√†n v·ªõi c∆° ch·∫ø gi·ªõi h·∫°n l·ª±c b·∫ª l√°i.
        """
        error = line_center_x - (self.WIDTH / 2)
        
        # V·∫´n ƒëi th·∫≥ng n·∫øu sai s·ªë r·∫•t nh·ªè
        if abs(error) < (self.WIDTH / 2) * self.SAFE_ZONE_PERCENT:
            self.robot.set_motors(self.BASE_SPEED, self.BASE_SPEED)
            return

        # T√≠nh to√°n l·ª±c ƒëi·ªÅu ch·ªânh
        adj = (error / (self.WIDTH / 2)) * self.CORRECTION_GAIN

        # NgƒÉn ch·∫∑n h√†nh vi b·∫ª l√°i qu√° g·∫Øt m·ªôt c√°ch tuy·ªát ƒë·ªëi
        adj = np.clip(adj, -self.MAX_CORRECTION_ADJ, self.MAX_CORRECTION_ADJ)
        
        # √Åp d·ª•ng l·ª±c ƒëi·ªÅu ch·ªânh ƒë√£ ƒë∆∞·ª£c gi·ªõi h·∫°n
        left_motor = self.BASE_SPEED + adj
        right_motor = self.BASE_SPEED - adj
        self.robot.set_motors(left_motor, right_motor)
        
    def handle_intersection(self):
        rospy.loginfo("\n[GIAO L·ªò] D·ª´ng l·∫°i v√† x·ª≠ l√Ω...")
        self.robot.stop(); time.sleep(0.5)

        current_direction = self.DIRECTIONS[self.current_direction_index]
        angle_to_sign = self.ANGLE_TO_FACE_SIGN_MAP.get(current_direction, 0)
        self.turn_robot(angle_to_sign, False)
        image_info = self.latest_image
        detections = self.detect_with_yolo(image_info)
        self.turn_robot(-angle_to_sign, False)
        
        prescriptive_cmds = {det['class_name'] for det in detections if det['class_name'] in self.PRESCRIPTIVE_SIGNS}
        prohibitive_cmds = {det['class_name'] for det in detections if det['class_name'] in self.PROHIBITIVE_SIGNS}
        data_items = [det for det in detections if det['class_name'] in self.DATA_ITEMS]

        # 2. X·ª≠ l√Ω c√°c m·ª•c d·ªØ li·ªáu (QR, To√°n) v√† Publish
        rospy.loginfo("[STEP 2] Processing data items...")
        for item in data_items:
            if item['class_name'] == 'qr_code':
                # Code ƒë·ªçc QR th·∫≠t
                # box = item['box']; qr_image = self.latest_image[box[1]:box[3], box[0]:box[2]]
                # decoded = decode(qr_image)
                # if decoded: qr_data = decoded[0].data.decode('utf-8'); self.publish_data(...)
                rospy.loginfo("Found QR Code. Publishing data...")
                self.publish_data({'type': 'QR_CODE', 'value': 'simulated_data_123'})

                # response = requests.post(url, json=data)

                # print(response.status_code)

            elif item['class_name'] == 'math_problem':
                rospy.loginfo("Found Math Problem. Solving and publishing...")
                self.publish_data({'type': 'MATH_PROBLEM', 'value': '2+2=4'})
        
        
        rospy.loginfo("[STEP 3] L·∫≠p k·∫ø ho·∫°ch ƒëi·ªÅu h∆∞·ªõng theo b·∫£n ƒë·ªì...")
        # 3. L·∫≠p k·∫ø ho·∫°ch ƒêi·ªÅu h∆∞·ªõng
        final_decision = None
        is_deviation = False 

        while True:
            planned_direction_label = self.navigator.get_next_direction_label(self.current_node_id, self.planned_path)
            if not planned_direction_label:
                rospy.logerr("L·ªói k·∫ø ho·∫°ch: Kh√¥ng t√¨m th·∫•y b∆∞·ªõc ti·∫øp theo."); self._set_state(RobotState.DEAD_END); return
            
            planned_action = self.map_absolute_to_relative(planned_direction_label, current_direction)
            rospy.loginfo(f"K·∫ø ho·∫°ch A* ƒë·ªÅ xu·∫•t: ƒêi {planned_action} (h∆∞·ªõng {planned_direction_label})")

            # ∆Øu ti√™n 1: Bi·ªÉn b√°o b·∫Øt bu·ªôc
            intended_action = None
            if 'L' in prescriptive_cmds: intended_action = 'left'
            elif 'R' in prescriptive_cmds: intended_action = 'right'
            elif 'F' in prescriptive_cmds: intended_action = 'straight'
            
            # ∆Øu ti√™n 2: Plan
            if intended_action is None:
                intended_action = planned_action
            else:
                # N·∫øu h√†nh ƒë·ªông b·∫Øt bu·ªôc kh√°c v·ªõi k·∫ø ho·∫°ch, ƒë√°nh d·∫•u l√† ƒëi ch·ªách h∆∞·ªõng
                if intended_action != planned_action:
                    is_deviation = True
                    rospy.logwarn(f"CH·ªÜCH H∆Ø·ªöNG! Bi·ªÉn b√°o b·∫Øt bu·ªôc ({intended_action}) kh√°c v·ªõi k·∫ø ho·∫°ch ({planned_action}).")

            # 3.3. Veto b·ªüi bi·ªÉn b√°o c·∫•m
            is_prohibited = (intended_action == 'straight' and 'NF' in prohibitive_cmds) or \
                            (intended_action == 'right' and 'NR' in prohibitive_cmds) or \
                            (intended_action == 'left' and 'NL' in prohibitive_cmds)

            if is_prohibited:
                rospy.logwarn(f"H√†nh ƒë·ªông d·ª± ƒë·ªãnh '{intended_action}' b·ªã C·∫§M!")
                
                # N·∫øu h√†nh ƒë·ªông b·ªã c·∫•m ƒë·∫øn t·ª´ bi·ªÉn b√°o b·∫Øt bu·ªôc -> L·ªói b·∫£n ƒë·ªì
                if is_deviation:
                    rospy.logerr("L·ªñI B·∫¢N ƒê·ªí! Bi·ªÉn b√°o b·∫Øt bu·ªôc m√¢u thu·∫´n v·ªõi bi·ªÉn b√°o c·∫•m. Kh√¥ng th·ªÉ ƒëi ti·∫øp.")
                    self._set_state(RobotState.DEAD_END); return
                
                # N·∫øu h√†nh ƒë·ªông b·ªã c·∫•m ƒë·∫øn t·ª´ k·∫ø ho·∫°ch A* -> T√¨m ƒë∆∞·ªùng l·∫°i
                banned_edge = (self.current_node_id, self.planned_path[self.planned_path.index(self.current_node_id) + 1])
                if banned_edge not in self.banned_edges:
                    self.banned_edges.append(banned_edge)
                
                rospy.loginfo(f"Th√™m c·∫°nh c·∫•m {banned_edge} v√† t√¨m ƒë∆∞·ªùng l·∫°i...")
                new_path = self.navigator.find_path(self.current_node_id, self.navigator.end_node, self.banned_edges)
                
                if new_path:
                    self.planned_path = new_path
                    rospy.loginfo(f"ƒê√£ t√¨m th·∫•y ƒë∆∞·ªùng ƒëi m·ªõi: {self.planned_path}")
                    continue # Quay l·∫°i ƒë·∫ßu v√≤ng l·∫∑p ƒë·ªÉ ki·ªÉm tra v·ªõi k·∫ø ho·∫°ch m·ªõi
                else:
                    rospy.logerr("Kh√¥ng th·ªÉ t√¨m ƒë∆∞·ªùng ƒëi m·ªõi sau khi g·∫∑p bi·ªÉn c·∫•m.")
                    self._set_state(RobotState.DEAD_END); return
            
            final_decision = intended_action
            break 

        # 4. Th·ª±c thi quy·∫øt ƒë·ªãnh
        if final_decision == 'straight': 
            rospy.loginfo("[FINAL] Decision: Go STRAIGHT.")
        elif final_decision == 'right': 
            rospy.loginfo("[FINAL] Decision: Turn RIGHT.") 
            self.turn_robot(90, True)
        elif final_decision == 'left': 
            rospy.loginfo("[FINAL] Decision: Turn LEFT.") 
            self.turn_robot(-90, True)
        else:
            rospy.logwarn("[!!!] DEAD END! No valid paths found.") 
            self._set_state(RobotState.DEAD_END)
            return
        
        # 5. C·∫≠p nh·∫≠t tr·∫°ng th√°i robot sau khi th·ª±c hi·ªán
        # 5.1. X√°c ƒë·ªãnh node ti·∫øp theo
        next_node_id = None
        if not is_deviation:
            # N·∫øu ƒëi theo k·∫ø ho·∫°ch, ch·ªâ c·∫ßn l·∫•y node ti·∫øp theo t·ª´ path
            next_node_id = self.planned_path[self.planned_path.index(self.current_node_id) + 1]
        else:
            # N·∫øu ch·ªách h∆∞·ªõng, ph·∫£i t√¨m node ti·∫øp theo d·ª±a tr√™n h√†nh ƒë·ªông ƒë√£ th·ª±c hi·ªán
            
            new_robot_direction = self.DIRECTIONS[self.current_direction_index] 
            
            executed_direction_label = None
            for label, direction_enum in self.LABEL_TO_DIRECTION_ENUM.items():
                if direction_enum == new_robot_direction:
                    executed_direction_label = label 
                    break
            
            if executed_direction_label is None:
                rospy.logerr("L·ªói logic: Kh√¥ng th·ªÉ t√¨m th·∫•y label cho h∆∞·ªõng ƒëi m·ªõi c·ªßa robot."); self._set_state(RobotState.DEAD_END) 
                return

            next_node_id = self.navigator.get_neighbor_by_direction(self.current_node_id, executed_direction_label)
            if next_node_id is None:
                 rospy.logerr("L·ªñI B·∫¢N ƒê·ªí! ƒê√£ th·ª±c hi·ªán r·∫Ω nh∆∞ng kh√¥ng c√≥ node t∆∞∆°ng ·ª©ng."); self._set_state(RobotState.DEAD_END); return
            
            # Quan tr·ªçng: L·∫≠p k·∫ø ho·∫°ch l·∫°i t·ª´ v·ªã tr√≠ m·ªõi
            rospy.loginfo(f"ƒê√£ ƒëi ch·ªách k·∫ø ho·∫°ch. L·∫≠p l·∫°i ƒë∆∞·ªùng ƒëi t·ª´ node m·ªõi {next_node_id}...")
            new_path = self.navigator.find_path(next_node_id, self.navigator.end_node, self.banned_edges)
            if new_path:
                self.planned_path = new_path
                rospy.loginfo(f"ƒê∆∞·ªùng ƒëi m·ªõi sau khi ch·ªách h∆∞·ªõng: {self.planned_path}")
            else:
                rospy.logerr("Kh√¥ng th·ªÉ t√¨m ƒë∆∞·ªùng v·ªÅ ƒë√≠ch t·ª´ v·ªã tr√≠ m·ªõi."); self._set_state(RobotState.DEAD_END); return

        self.target_node_id = next_node_id
        rospy.loginfo(f"==> ƒêang di chuy·ªÉn ƒë·∫øn node ti·∫øp theo: {self.target_node_id}")
        self._set_state(RobotState.LEAVING_INTERSECTION)
    
    def turn_robot(self, degrees, update_main_direction=True):
        duration = abs(degrees) / 90.0 * self.TURN_DURATION_90_DEG
        if degrees > 0: 
            self.robot.set_motors(self.TURN_SPEED, -self.TURN_SPEED)
        elif degrees < 0: 
            self.robot.set_motors(-self.TURN_SPEED, self.TURN_SPEED)
        if degrees != 0: 
            time.sleep(duration)
        self.robot.stop()
        if update_main_direction and degrees % 90 == 0 and degrees != 0:
            num_turns = round(degrees / 90)
            self.current_direction_index = (self.current_direction_index + num_turns + 4) % 4
            rospy.loginfo(f"==> H∆∞·ªõng ƒëi M·ªöI: {self.DIRECTIONS[self.current_direction_index].name}")
        time.sleep(0.5)
    
    def _does_path_exist_in_frame(self, image):
        if image is None: return False
        roi = image[self.ROI_Y : self.ROI_Y + self.ROI_H, :]
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, self.LINE_COLOR_LOWER, self.LINE_COLOR_UPPER)
        _img, contours, _hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        return bool(contours) and cv2.contourArea(max(contours, key=cv2.contourArea)) > self.SCAN_PIXEL_THRESHOLD
    
    def scan_for_available_paths_proactive(self):
        rospy.loginfo("[SCAN] B·∫Øt ƒë·∫ßu qu√©t ch·ªß ƒë·ªông...")
        paths = {"straight": False, "right": False, "left": False}
        if self.latest_image is not None:
            paths["straight"] = self._does_path_exist_in_frame(self.latest_image)
        self.turn_robot(90, update_main_direction=False); time.sleep(0.5)
        if self.latest_image is not None:
            paths["right"] = self._does_path_exist_in_frame(self.latest_image)
        self.turn_robot(-180, update_main_direction=False); time.sleep(0.5)
        if self.latest_image is not None:
            paths["left"] = self._does_path_exist_in_frame(self.latest_image)
        self.turn_robot(90, update_main_direction=False)
        rospy.loginfo(f"[SCAN] K·∫øt qu·∫£: {paths}")
        return paths

def main():
    rospy.init_node('jetbot_controller_node', anonymous=True)
    try:
        controller = JetBotController()
        controller.run()
    except rospy.ROSInterruptException: rospy.loginfo("Node ƒë√£ b·ªã ng·∫Øt.")
    except Exception as e: rospy.logerr(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}", exc_info=True)

if __name__ == '__main__':
    main()